\documentclass[12pt]{article}

\usepackage{hyperref}

\begin{document}

\title{Hypothesis}
\author{Shiro Takagi}
\date{2021/4/12}
\maketitle

\section{question}
Q: How to make an intelligent system that learns to manipulate symbols?

\section{survey}

\subsection{cognitive science}
Chomsky says that the power to taming syntax is innate property of 
human brain (universal grammar) \cite{Chomsky02}. 
Ibbotson says that ``the complexity of language emerges 
not as a result of a language-specific instinct 
but through the interaction of cognition and use" (usage-based theory) 
\cite{Ibbotson13}. According to the usage-based theory, linguistic 
structure develops by 1. categorization, 2. chunking, 3. rich memory, 
4. analogy, and 5. cross-modal association \cite{Bybee10,Ibbotson13}.
Children use a limited number of reliable short frames.


``
\textit{Overall it seems there is good evidence to support the usage-based 
prediction that language structure emerges in ontogeny out of 
experience (viz. use) and when a child uses core usage-based cognitive 
processes – categorization, analogy, form-meaning mapping, chunking, 
exemplar/item-based representations – to find and use communicatively 
meaningful units.} \cite{Ibbotson13}
"

The meaning of symbols is established by convention \cite{Santoro21,Taniguchi18,Mcclelland20}. 


\subsection{transformers}
Transformer learns syntactic information \cite{Reif19,Hewitt19,Goldberg19,Tenney19}.

\subsection{comparative study}
Watson et al. claims that ``\textit{nonadjacent dependency processing, a crucial cognitive facilitator 
of language, is an ancestral trait that evolved at least ~40 million years before language itself}'' \cite{Watson20}. 
Wilson et al. explains that sufficient cues play crucial role for human nonadjacent dependency learning \cite{Wilson20}.
Okanoya and Merker propose the hypothesis that human language is established through string-context 
mutual segmentation: ``\textit{song strings and behavioral contexts are mutually segmented
during social interactions}'' \cite{Okanoya07}. 

\subsection{Neo-Vygotskian Theory}
\textit{The key novelties in human evolution were all, in one way or another, adaptations for an especially 
cooperative, indeed hypercooperative, way of life} \cite{Tomasello19}. Tomasello states that there 
are two human-unique capabilities: joint intentionality and collective intentionality. He says that 
Human developed preparation for these abilities and children first acquire joint intention and then 
collective intention in their developmental stages.

\section{Discussion}
\subsection{transformers}
If transformers really capture syntax, \textbf{how it develops the syntactic representation during the pre-training? }
Previous studies seem to find that pre-trained transformer have syntactic representation but how to do that remains 
to be answered. If I can single out the cause of the syntax emergence, I may be able to model a guiding principle 
for an intelligent agent to learn syntax.

\subsection{syntax}
It might be plausible that infants first identify phrases in sentences. To identify phrases, it might be necessary 
that the phrase is used in multiple sentences. By observing the subset of sentences in multiple sentences repeatedly, 
infants could identify which subset is the the phrase. However, a phrase less likely to appear many times in multiple contexts. 
Thus, I could hypothesize that infants first understand too common and too often appearing phrase. Then, they 
understand that theres is the concept ``phrase" in their society. Finally, they could start to generalize their knowledge 
and to do try and error to manipulate phrase order. In sum,\textbf{ I hypothesize that artificial intelligence should 
follow the following path for language acquisition: phrase identification - phrase order arrangement - phrase manipulation. }
If this is the case, I should create an environment where identifying key phrase will give reword to the agent. 
This view is similar to that in \cite{Okanoya07} which I explained above.

\subsection{keyword detection}
Dual-coding memory may be a key because visual information is pseudo label there \cite{Hill21}.
Even if no instructor exists, the agent can learns the concept him/herself.

\subsection{collective intention}
A distinct feature of human intelligence is its mastery of languages. On the other hand, 
Tomasello argues that humans differ from other animals in terms of collective intentionality.
If this is the case, \textbf{a natural hypothesis from this is that human develop language skills 
thanks to their collective intentionality.}

\subsection{Action and Symbolic Manipulation}
Human understand a notion of ``research'' and know that it includes ``science'', for example. 
Or, I can use a more abstract notion of ``object'' and apply an ``operation'' on it. Human beings 
seem to excel at these symbolic manipulation. I believe that memory is ``used'' for these operations. 

I support the view that the semantics of neural representation is designed through the culture 
the agent is in \cite{Santoro21}. Repeated activations of neurons constructs an abstract concept 
and the symbols are attached to these concepts and segments the neural representation space. 
Thus, the abstract concept is formed through energy minimization and semantics is grounded to these 
abstract through social interactions. I hypothesize that human attach the symbol because it 
improves the predictability of internal and external states. In other words, I do so 
because it is useful. I think that the relation is also formed through this process.

\textbf{I think that the symbolic operation is a generalization 
of the physical action in the neural representation space.} When I move a cup, the cup will change 
its position after the action. In the similar vein, I act on a symbol and produce another symbol. 
Planning, making a hypothesis, proving a proposition, all of these mental actions can be 
regarded as like this. I find a book that presents a similar idea a bit \cite{Hawkins21}. 
Also, the idea of \textit{motor control origin of Merge} presented in \cite{Fujita14,Fujita17} 
proposed a similar view. There are some counter arguments on this view as well \cite{Zaccarella21}. 
This kind of idea seems to have its long history \cite{Lashley51,Greenfield91}. I also think that symbolic operation occurs just because it is ``useful''.

Therefore, I believe that the temporal characteristics of the environment humans live in matters 
for symbolic manipulation.
% \section{Note}
% As Shannon pointed out, this kind of redundancy allows recovery of meaning 
% xvxn whxn thx sxgnxl xs nxxsy <-- Masked Language Model? \cite{Shannon51}
% Syntax representation development during pre-training is left for future study.
% should memory be multi-modal?

\subsection{Language and Localization}
A research proposes an interesting view on localization of human language function in our brain \cite{Macneilage09}. 
They say that ``\textit{our hypothesis holds that the left
hemisphere of the vertebrate brain was originally specialized for the control of well-established
patterns of behavior under ordinary and familiar circumstances. In contrast, the right hemisphere, 
the primary seat of emotional arousal, was at first specialized for detecting and responding to 
unexpected stimuli in the environment ...  In other words, the left hemisphere became the seat of self-motivated behavior, sometimes called top-down control. (We
stress that self-motivated behavior need not be
innate; in fact, it is often learned.) The right
hemisphere became the seat of environmentally
motivated behavior, or bottom-up control.}'' \cite{Macneilage09}. 
This view is consistent with 
\cite{Okanoya07}, where authors emphasize the importance of ``song'' and repeated phrases for 
the emergence of human language. An important implication from this literature is the 
connections among repeated action, top-down control, and language. 
\textbf{An intelligent agent may come to manipulate symbols after gaining top-down control through 
repeated actions.} 

They present another interesting observation. They note that ``\textit{In humans the right hemisphere
“takes in the whole scene,” attending to the global aspects of its environment 
rather than focusing on a limited number of features. That capacity gives it substantial advantages in analyzing
spatial relations. Memories stored by the right hemisphere tend to be organized and recalled as overall patterns 
rather than as a series of single items. In contrast, the left hemisphere tends to
focus on local aspects of its environment.}'' \textbf{If this is the case, I may assume that 
locality preference bias may be a good starting point for nurturing symbolic manipulations.}

They also hypothesize that ``\textit{to assess an incoming stimulus, an organism must carry out two kinds of analyses simultaneously. 
It must estimate the overall novelty of the stimulus and take decisive emergency action
if needed (right hemisphere). And it must determine whether the stimulus fits some familiar category, 
so as to make whatever well-established response, if any, is called for (left hemisphere).}'' 
\textbf{If I adopt this view, I may say that I can assume two kind of intrinsic motivations. 
One is the preference for the novelty, which is studied for a long time \cite{Schmidhuber10}. 
The other is the preference for categorization, which is not explored but can be important for 
higher cognitive functions.} They also say that ``\textit{Perhaps, then, those hemispheric specializations 
initially evolved because collectively they do a more efficient job of processing both kinds
of information at the same time than a brain without such specialized systems.}'' 

\subsection{Language and Brain}
I find \cite{Friederici17} really good read. The author describe the ontogeny of the 
linguistic skills of human children. 

Under age 3, the author state that 
``\textit{The available data from the neurocognitive studies reviewed in this section provide consistent
evidence that very early on an infant is able to extract language-relevant information
from the acoustic input. Infants appear to be equipped with the ability to identify those
language sounds relevant for the phonetics of the target language, to perceive prosodic cues
that allow them to chunk the input into phrases, and to recognize positional regularities and
dependencies that are crucial for the syntax of the target language. Moreover, associative
learning allows infants to rapidly acquire names of objects and actions, and the relation
between them. All the processes mainly involve the temporal cortices of both hemispheres
with a shift toward the left hemisphere with increasing age.}''

She also says that ``The findings provide suggestive evidence that the full
language capacity can only be reached once the brain has fully matured.'' For syntactic ability, 
she find that ``\textit{the dorsal fiber tract
connecting BA 44 in the inferior frontal gyrus to the posterior temporal cortex is crucial for
the full achievement of syntactic abilities.}'' 

She points out the relations of semantics and syntax in human ontogeny. She 
says that : ``\textit{3- to 4- and 6- to 7-year-old children, in contrast to
adults, do not process syntax independently from semantics as indicated by their activation
pattern. Semantics and syntax interacted with each other in the superior temporal cortex.
Interestingly, it is not until the end of the 10th year of life that children show a neural selectivity
for syntax, segregated and independent from semantics, in the left inferior frontal
gyrus similar to activation patterns seen in the adult brain. Thus, for processing the more
complex object-first sentences compared to the less complex subject-first sentences, it is
not until early adolescence that a domain-specific selectivity of syntax can be observed at
the brain level.}''

She summarizes these findings as follows: 
``\textit{during the
first months of life, language processing is largely input-driven and supported by the temporal
cortex and the ventral part of the language network. Beyond the age of 3 years, when
top-down processes come into play, the left inferior frontal cortex and the dorsal part of the
language network are recruited to a larger extent.}'' An important point of this is 
linguistic capability on semantics develops faster than that on syntax. This implies that 
\textbf{I should have agents to learn semantics first to develop their symbol manipulation skills.}

The author also discuss language evolution. She introduces a classical view on language development that 
language development can be related to imitation because Broca’s area is related with both 
mirror system and language \cite{Iacoboni99,Iacoboni05}. Though the validity of this theory seem to be 
under debase and the author of the book takes a negative position on this view, I find the hypothesis 
interesting and promising. 

By comparing human and non-human, the author clarifies an important distinction: 
``\textit{During the evolution of language two crucial abilities had to evolve: these are first, sensorymotor
learning, and second, the ability to process hierarchical structures. Sensory-motor
learning of simple rule-based sequences is an ability that is present songbirds. However,
the ability to process hierarchical structures is not present in songbirds. Therefore, it is
conceivable that the ability to process structural hierarchies is what should be considered
as a crucial step toward the language faculty.}'' If this were the case, \textbf{I may have to consider how to 
install the ability to process structural hierarchies for the agent.} 

She finds the structural differences between human brain and non-human brain indicate the human 
faculty on syntax processing: ``\textit{First, cytoarchitectonic analyses demonstrate a leftward asymmetry
of Broca’s area in the inferior frontal gyrus in humans, but not in non-human primates.
Second, the dorsal connection between BA 44 in Broca’s area and the superior temporal
cortex is stronger in the human brain than in the non-human primate brain. These structures may have 
evolved to subserve the human capacity to process syntax, which is at the core of the human language faculty.}''

I put the summary of this book below: ``\textit{Humans differ from non-human primates in their ability to build syntactic structures. This
statement has set the scene for our assessment of language in this book. Many sections of
Language in Our Brain have focused on syntax, and yet our feeling—when considering
language—may rather tend to favor semantics and meaning as the most important aspects
of language. We do, after all, want to communicate meaning. In order to do so, however,
we need syntax to combine words into phrases and sentences. ... 
Language is what enables us to plan the future together with others, and to learn from the
past through narratives. Language forms the basis of our social and cultural interaction not
only in the “here and now,” but most importantly also in the “there and then.”
This evolutionary step is realized in a brain that—as far as we know—underwent only
minor, although important changes compared to our closest relatives. I have argued that
the syntactic specificity of Broca’s area, in particular its posterior part, namely BA 44 and
its connection to the temporal cortex granting the interplay between these two regions, is
what accounts for one of these changes. From an evolutionary perspective it remains an
open question whether humans develop language to cover those needs and whether the
emergence of language determined the homo loquens as a cultural being.}''

\subsection{Recursive Merge and Displacement}
Hauser et al. propose a hypothesis that the only unique properties of human language are 
\textit{recursive merge } and \textit{displacement} \cite{Hauser02}.

\subsection{Environment}
It matters to consider what situation is good for developing language ability. For 
example, if you an agent is in a simple environment and it has only one action, it 
might not have to learn complex signal like language.

\section{Hypotheses}
In sum, I hypothesize that following things are important to make agents 
learn to process symbols:
\begin{itemize}
    \item Mastery of compositional/hierarchical physical action
    \item Preference on repetition, locality, and categorization
    \item Rich capacity to understand semantics
    \item Collective intention
    \item Preference on complex chunk arrangement
    \item Statistical learning of syntax from texts/speech
\end{itemize}
I will evaluate these hypotheses one by one.

\section{A Probable path toward human faculty of language}
The basic function of the brain is prediction. I hypothesize that every function 
of human brain can be explained as prediction. When an agent is exposed to 
an environment, it first learns the intuitive physics of the world by prediction. 
Because finding the pattern is the best for prediction, the agent naturally learn o extract 
patterns from the world. As a result, the agent forms an abstract concept of the objects in the world. 
This is a precursor of the symbol. This is supported by the preference on repetition and categorization, 
which is installed in human brain, especially in the left side of it. 

This conceptualization is applicable to actions as well. Human can acquire an abstract 
notion of action by repetition and categorization. Then, they can combine several actions 
and form another action. They can use this constructed action to compose another action. 
In this way, human learn to construct hierarchical action. This is a physical manifestation of 
recursive merge, an important characteristics of language. At this point, 
human get the precursors for symbolization and its operation. 

Because humans are social animal, they communicate with each other. Communication arises because 
it is useful for them to live in the world. Without communication, abstract concept can be in any form 
as long as it makes sense to him/herself. However, once you have to communicate with others, the 
abstract concept should be grounded to something common to the members, symbol. 
Thus, they define symbols and semantics attached to them 
through cultural interaction. The first time to name a semantics as a symbol is important 
since one the agents do so, it can learn the action of naming symbol itself. The agents might to 
this by string-context mutual segmentation. 

This development is necessary in evolution process. However, in the human ontogeny, infants are 
exposed to language spoken by other humans. Thus, it is easier to learn semantics and syntax. 
Infants can associate linguistic semantics with abstract concept. Syntax is also learned from 
tons of demonstration of human language. In addition, since phonological segmentation of a sentence 
is tightly connected with syntactic information, it makes easier children to learn syntax.

\textbf{In this whole process, what I think particularly important are abilities/properties to learn hierarchical pattern 
and compose hierarchical actions.}

\bibliography{ref}
\bibliographystyle{unsrt}

\end{document}